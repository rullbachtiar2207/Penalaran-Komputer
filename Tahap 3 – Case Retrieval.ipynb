{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0g9yAQ_tBzi",
        "outputId": "d04e1d22-b48d-496e-b6c5-05a4a05342da"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDfWyh4qs54r",
        "outputId": "5d200bdf-19c6-444f-d7d8-a005c4a7a5f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Dataset loaded: 117 cases\n",
            "Data preprocessing completed\n",
            "Data shape: (117, 24)\n",
            "Columns: ['case_id', 'no_perkara', 'tanggal', 'jenis_perkara', 'pasal', 'pihak', 'penggugat', 'tergugat', 'filename', 'ringkasan_fakta', 'argumen_hukum', 'putusan', 'barang_bukti', 'text_length', 'word_count', 'clean_word_count', 'top_words', 'legal_terms', 'sentence_count', 'text_full', 'qa_pairs', 'processing_date', 'combined_text', 'retrieval_text']\n",
            "\n",
            "Jenis Perkara distribution:\n",
            "jenis_perkara\n",
            "perkara pidana                                   82\n",
            "Pid.Sus                                          10\n",
            "PID.SUS                                           5\n",
            "perkara perdata                                   2\n",
            "Pdt.G                                             2\n",
            "perkara Pidana                                    1\n",
            "PID.SUS                                           1\n",
            "Pid.I.A.1.3 R a i P U T U S A N s M Nomor 278     1\n",
            "Pid.I.A.3 R a i P U T U S A N s M Nomor 759       1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Creating TF-IDF Representation ===\n",
            "Creating TF-IDF representation...\n",
            "TF-IDF matrix shape: (117, 2353)\n",
            "\n",
            "=== Creating BERT Representation ===\n",
            "Loading BERT model: indobenchmark/indobert-base-p1\n",
            "Creating BERT embeddings...\n",
            "Processing 1/117 cases...\n",
            "Processing 11/117 cases...\n",
            "Processing 21/117 cases...\n",
            "Processing 31/117 cases...\n",
            "Processing 41/117 cases...\n",
            "Processing 51/117 cases...\n",
            "Processing 61/117 cases...\n",
            "Processing 71/117 cases...\n",
            "Processing 81/117 cases...\n",
            "Processing 91/117 cases...\n",
            "Processing 101/117 cases...\n",
            "Processing 111/117 cases...\n",
            "BERT embeddings shape: (117, 768)\n",
            "\n",
            "=== Splitting Data ===\n",
            "Splitting data with ratio 0.7:0.3\n",
            "Class distribution:\n",
            "jenis_perkara\n",
            "perkara pidana                                   82\n",
            "unknown                                          12\n",
            "Pid.Sus                                          10\n",
            "PID.SUS                                           5\n",
            "perkara perdata                                   2\n",
            "Pdt.G                                             2\n",
            "perkara Pidana                                    1\n",
            "PID.SUS                                           1\n",
            "Pid.I.A.1.3 R a i P U T U S A N s M Nomor 278     1\n",
            "Pid.I.A.3 R a i P U T U S A N s M Nomor 759       1\n",
            "Name: count, dtype: int64\n",
            "Using random split (stratification not possible due to class imbalance)\n",
            "Training set: 81 cases\n",
            "Test set: 36 cases\n",
            "Training set class distribution:\n",
            "jenis_perkara\n",
            "perkara pidana                                   58\n",
            "unknown                                          10\n",
            "Pid.Sus                                           4\n",
            "PID.SUS                                           3\n",
            "perkara perdata                                   2\n",
            "perkara Pidana                                    1\n",
            "Pid.I.A.1.3 R a i P U T U S A N s M Nomor 278     1\n",
            "Pid.I.A.3 R a i P U T U S A N s M Nomor 759       1\n",
            "Pdt.G                                             1\n",
            "Name: count, dtype: int64\n",
            "Test set class distribution:\n",
            "jenis_perkara\n",
            "perkara pidana    24\n",
            "Pid.Sus            6\n",
            "unknown            2\n",
            "PID.SUS            2\n",
            "PID.SUS            1\n",
            "Pdt.G              1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Training ML Model ===\n",
            "Training SVM model...\n",
            "Training Accuracy: 0.9136\n",
            "Test Accuracy: 0.8056\n",
            "\n",
            "Detailed Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "       PID.SUS       0.00      0.00      0.00         2\n",
            "      PID.SUS        0.00      0.00      0.00         1\n",
            "         Pdt.G       0.00      0.00      0.00         1\n",
            "       Pid.Sus       1.00      0.50      0.67         6\n",
            "perkara pidana       0.77      1.00      0.87        24\n",
            "       unknown       1.00      1.00      1.00         2\n",
            "\n",
            "      accuracy                           0.81        36\n",
            "     macro avg       0.46      0.42      0.42        36\n",
            "  weighted avg       0.74      0.81      0.75        36\n",
            "\n",
            "\n",
            "=== Creating Test Queries ===\n",
            "Creating 10 test queries...\n",
            "Created 10 test queries\n",
            "Test queries saved to /content/drive/MyDrive/PENALARAN KOMPUTER FIX/data/eval/queries.json\n",
            "\n",
            "=== Evaluating TF-IDF Retrieval ===\n",
            "Evaluating retrieval with tfidf method...\n",
            "TF-IDF Metrics: {'hits_at_1': 0.0, 'hits_at_5': 0.0, 'mrr': np.float64(0.0), 'total_queries': 10}\n",
            "\n",
            "=== Evaluating BERT Retrieval ===\n",
            "Evaluating retrieval with bert method...\n",
            "BERT Metrics: {'hits_at_1': 0.1, 'hits_at_5': 0.2, 'mrr': np.float64(0.12), 'total_queries': 10}\n",
            "\n",
            "=== Testing Retrieval Function ===\n",
            "\n",
            "==================================================\n",
            "Query: kasus perceraian dengan harta gono gini\n",
            "==================================================\n",
            "\n",
            "TF-IDF Results:\n",
            "1. Case ID: zaf04b45424b7372a05c313333353238, Score: 0.0000\n",
            "   Jenis Perkara: perkara pidana\n",
            "   Pasal: 22 ayat, 112 ayat, 114 ayat\n",
            "   Ringkasan: nan...\n",
            "\n",
            "2. Case ID: zaf04b86ee60f60abfbb323132353334, Score: 0.0000\n",
            "   Jenis Perkara: perkara pidana\n",
            "   Pasal: 43 ayant, 112 ayat, 114 ayat\n",
            "   Ringkasan: nan...\n",
            "\n",
            "3. Case ID: zaf04c0481e1c684874f313232343239, Score: 0.0000\n",
            "   Jenis Perkara: perkara pidana\n",
            "   Pasal: 21 jo, 241 ayat, 114 Ayat\n",
            "   Ringkasan: nan...\n",
            "\n",
            "BERT Results:\n",
            "1. Case ID: zaf04bdb038c189e9da5303732373237, Score: 0.5115\n",
            "   Jenis Perkara: perkara pidana\n",
            "   Pasal: 127 ayat n A, 8 ayat, 112 ayat n n, 36 nayat, 112 ayat\n",
            "   Ringkasan: nan...\n",
            "\n",
            "2. Case ID: zaf04b56c9d89340b4ef313534303537, Score: 0.4590\n",
            "   Jenis Perkara: perkara pidana\n",
            "   Pasal: 114 ayat, 112 Ayat, 132 ayat, 114 Ayat\n",
            "   Ringkasan: nan...\n",
            "\n",
            "3. Case ID: zaf04b2fc1646468994f313130313332, Score: 0.4497\n",
            "   Jenis Perkara: perkara pidana\n",
            "   Pasal: 112 ayat, 132 ayat, 114 ayat\n",
            "   Ringkasan: nan...\n",
            "\n",
            "\n",
            "==================================================\n",
            "Query: sengketa kontrak kerja\n",
            "==================================================\n",
            "\n",
            "TF-IDF Results:\n",
            "1. Case ID: zaf04b45424b7372a05c313333353238, Score: 0.0000\n",
            "   Jenis Perkara: perkara pidana\n",
            "   Pasal: 22 ayat, 112 ayat, 114 ayat\n",
            "   Ringkasan: nan...\n",
            "\n",
            "2. Case ID: zaf04b86ee60f60abfbb323132353334, Score: 0.0000\n",
            "   Jenis Perkara: perkara pidana\n",
            "   Pasal: 43 ayant, 112 ayat, 114 ayat\n",
            "   Ringkasan: nan...\n",
            "\n",
            "3. Case ID: zaf04c0481e1c684874f313232343239, Score: 0.0000\n",
            "   Jenis Perkara: perkara pidana\n",
            "   Pasal: 21 jo, 241 ayat, 114 Ayat\n",
            "   Ringkasan: nan...\n",
            "\n",
            "BERT Results:\n",
            "1. Case ID: zaf04bdb038c189e9da5303732373237, Score: 0.3855\n",
            "   Jenis Perkara: perkara pidana\n",
            "   Pasal: 127 ayat n A, 8 ayat, 112 ayat n n, 36 nayat, 112 ayat\n",
            "   Ringkasan: nan...\n",
            "\n",
            "2. Case ID: zaf04b2fc1646468994f313130313332, Score: 0.3602\n",
            "   Jenis Perkara: perkara pidana\n",
            "   Pasal: 112 ayat, 132 ayat, 114 ayat\n",
            "   Ringkasan: nan...\n",
            "\n",
            "3. Case ID: zaf0370dfb24dede910a323030393233, Score: 0.3485\n",
            "   Jenis Perkara: Pid.Sus\n",
            "   Pasal: 141 juncto Pasal, 197 Ayat, 89 Undang, 8 Ayat\n",
            "   Ringkasan: nan...\n",
            "\n",
            "\n",
            "============================================================\n",
            "=== Case Retrieval System Setup Complete ===\n",
            "============================================================\n",
            "System summary saved to /content/drive/MyDrive/PENALARAN KOMPUTER FIX/data/eval/system_summary.json\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class CaseRetrievalSystem:\n",
        "    def __init__(self, dataset_path):\n",
        "        \"\"\"\n",
        "        Initialize Case Retrieval System\n",
        "\n",
        "        Args:\n",
        "            dataset_path (str): Path to the cases.csv dataset\n",
        "        \"\"\"\n",
        "        self.dataset_path = dataset_path\n",
        "        self.df = None\n",
        "        self.tfidf_vectorizer = None\n",
        "        self.tfidf_matrix = None\n",
        "        self.bert_tokenizer = None\n",
        "        self.bert_model = None\n",
        "        self.bert_embeddings = None\n",
        "        self.ml_model = None\n",
        "        self.X_train = None\n",
        "        self.X_test = None\n",
        "        self.y_train = None\n",
        "        self.y_test = None\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"Load and preprocess the dataset\"\"\"\n",
        "        print(\"Loading dataset...\")\n",
        "        self.df = pd.read_csv(self.dataset_path)\n",
        "        print(f\"Dataset loaded: {len(self.df)} cases\")\n",
        "\n",
        "        # Combine relevant text fields for analysis\n",
        "        text_columns = ['ringkasan_fakta', 'argumen_hukum', 'putusan', 'barang_bukti']\n",
        "        self.df['combined_text'] = self.df[text_columns].fillna('').apply(\n",
        "            lambda x: ' '.join(x.astype(str)), axis=1\n",
        "        )\n",
        "\n",
        "        # Use text_full if available, otherwise use combined_text\n",
        "        if 'text_full' in self.df.columns:\n",
        "            self.df['retrieval_text'] = self.df['text_full'].fillna(self.df['combined_text'])\n",
        "        else:\n",
        "            self.df['retrieval_text'] = self.df['combined_text']\n",
        "\n",
        "        # Create case IDs if not present\n",
        "        if 'case_id' not in self.df.columns:\n",
        "            self.df['case_id'] = ['case_' + str(i).zfill(4) for i in range(len(self.df))]\n",
        "\n",
        "        print(\"Data preprocessing completed\")\n",
        "        return self.df\n",
        "\n",
        "    def create_tfidf_representation(self, max_features=5000):\n",
        "        \"\"\"\n",
        "        Create TF-IDF representation of the cases\n",
        "\n",
        "        Args:\n",
        "            max_features (int): Maximum number of features for TF-IDF\n",
        "        \"\"\"\n",
        "        print(\"Creating TF-IDF representation...\")\n",
        "\n",
        "        self.tfidf_vectorizer = TfidfVectorizer(\n",
        "            max_features=max_features,\n",
        "            stop_words=None,  # You can add Indonesian stop words here\n",
        "            ngram_range=(1, 2),\n",
        "            min_df=2,\n",
        "            max_df=0.8\n",
        "        )\n",
        "\n",
        "        self.tfidf_matrix = self.tfidf_vectorizer.fit_transform(self.df['retrieval_text'])\n",
        "        print(f\"TF-IDF matrix shape: {self.tfidf_matrix.shape}\")\n",
        "        return self.tfidf_matrix\n",
        "\n",
        "    def create_bert_representation(self, model_name='indobenchmark/indobert-base-p1'):\n",
        "        \"\"\"\n",
        "        Create BERT embeddings for the cases\n",
        "\n",
        "        Args:\n",
        "            model_name (str): Pre-trained BERT model name\n",
        "        \"\"\"\n",
        "        print(f\"Loading BERT model: {model_name}\")\n",
        "\n",
        "        try:\n",
        "            self.bert_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "            self.bert_model = AutoModel.from_pretrained(model_name)\n",
        "            self.bert_model.eval()\n",
        "        except:\n",
        "            print(\"Failed to load IndoBERT, using multilingual BERT instead...\")\n",
        "            model_name = 'bert-base-multilingual-cased'\n",
        "            self.bert_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "            self.bert_model = AutoModel.from_pretrained(model_name)\n",
        "            self.bert_model.eval()\n",
        "\n",
        "        print(\"Creating BERT embeddings...\")\n",
        "        embeddings = []\n",
        "\n",
        "        for idx, text in enumerate(self.df['retrieval_text']):\n",
        "            if idx % 10 == 0:\n",
        "                print(f\"Processing {idx+1}/{len(self.df)} cases...\")\n",
        "\n",
        "            # Truncate text to avoid memory issues\n",
        "            text = str(text)[:512]\n",
        "\n",
        "            # Tokenize and encode\n",
        "            inputs = self.bert_tokenizer(\n",
        "                text,\n",
        "                return_tensors='pt',\n",
        "                truncation=True,\n",
        "                padding=True,\n",
        "                max_length=512\n",
        "            )\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.bert_model(**inputs)\n",
        "                # Use CLS token embedding\n",
        "                embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
        "                embeddings.append(embedding)\n",
        "\n",
        "        self.bert_embeddings = np.array(embeddings)\n",
        "        print(f\"BERT embeddings shape: {self.bert_embeddings.shape}\")\n",
        "        return self.bert_embeddings\n",
        "\n",
        "    def split_data(self, test_size=0.3, random_state=42):\n",
        "        \"\"\"\n",
        "        Split data for training and testing\n",
        "\n",
        "        Args:\n",
        "            test_size (float): Proportion of test data\n",
        "            random_state (int): Random seed\n",
        "        \"\"\"\n",
        "        print(f\"Splitting data with ratio {1-test_size:.1f}:{test_size:.1f}\")\n",
        "\n",
        "        # Use jenis_perkara as target for classification\n",
        "        y = self.df['jenis_perkara'].fillna('unknown')\n",
        "\n",
        "        # Check class distribution\n",
        "        class_counts = y.value_counts()\n",
        "        print(f\"Class distribution:\\n{class_counts}\")\n",
        "\n",
        "        # FIX: Use .values to get numpy array, then check all elements\n",
        "        class_count_values = class_counts.values  # This is already a numpy array\n",
        "        can_stratify = all(count >= 2 for count in class_count_values)\n",
        "\n",
        "        # Check if stratification is possible\n",
        "        if can_stratify and len(y.unique()) > 1:\n",
        "            print(\"Using stratified split\")\n",
        "            stratify_param = y\n",
        "        else:\n",
        "            print(\"Using random split (stratification not possible due to class imbalance)\")\n",
        "            stratify_param = None\n",
        "\n",
        "        # Split using TF-IDF features\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
        "            self.tfidf_matrix.toarray(),\n",
        "            y,\n",
        "            test_size=test_size,\n",
        "            random_state=random_state,\n",
        "            stratify=stratify_param\n",
        "        )\n",
        "\n",
        "        print(f\"Training set: {self.X_train.shape[0]} cases\")\n",
        "        print(f\"Test set: {self.X_test.shape[0]} cases\")\n",
        "        print(f\"Training set class distribution:\\n{pd.Series(self.y_train).value_counts()}\")\n",
        "        print(f\"Test set class distribution:\\n{pd.Series(self.y_test).value_counts()}\")\n",
        "\n",
        "        return self.X_train, self.X_test, self.y_train, self.y_test\n",
        "\n",
        "    def train_ml_model(self, model_type='svm'):\n",
        "        \"\"\"\n",
        "        Train machine learning model for retrieval\n",
        "\n",
        "        Args:\n",
        "            model_type (str): 'svm' or 'naive_bayes'\n",
        "        \"\"\"\n",
        "        print(f\"Training {model_type.upper()} model...\")\n",
        "\n",
        "        # Check if we have enough classes and samples for training\n",
        "        unique_classes = len(set(self.y_train))\n",
        "        if unique_classes < 2:\n",
        "            print(\"Warning: Only one class in training data. Skipping ML model training.\")\n",
        "            return None\n",
        "\n",
        "        if model_type.lower() == 'svm':\n",
        "            # Use different kernel for small datasets\n",
        "            if len(self.y_train) < 100:\n",
        "                self.ml_model = SVC(kernel='rbf', probability=True, random_state=42, C=1.0)\n",
        "            else:\n",
        "                self.ml_model = SVC(kernel='linear', probability=True, random_state=42)\n",
        "        elif model_type.lower() == 'naive_bayes':\n",
        "            self.ml_model = MultinomialNB(alpha=1.0)\n",
        "        else:\n",
        "            raise ValueError(\"model_type must be 'svm' or 'naive_bayes'\")\n",
        "\n",
        "        try:\n",
        "            self.ml_model.fit(self.X_train, self.y_train)\n",
        "\n",
        "            # Evaluate model\n",
        "            train_pred = self.ml_model.predict(self.X_train)\n",
        "            test_pred = self.ml_model.predict(self.X_test)\n",
        "\n",
        "            print(f\"Training Accuracy: {accuracy_score(self.y_train, train_pred):.4f}\")\n",
        "            print(f\"Test Accuracy: {accuracy_score(self.y_test, test_pred):.4f}\")\n",
        "\n",
        "            # Show detailed classification report for test set\n",
        "            print(\"\\nDetailed Classification Report:\")\n",
        "            print(classification_report(self.y_test, test_pred, zero_division=0))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error training model: {e}\")\n",
        "            print(\"Continuing without ML model...\")\n",
        "            self.ml_model = None\n",
        "\n",
        "        return self.ml_model\n",
        "\n",
        "    def retrieve_tfidf(self, query_text, top_k=5):\n",
        "        \"\"\"\n",
        "        Retrieve similar cases using TF-IDF and cosine similarity\n",
        "\n",
        "        Args:\n",
        "            query_text (str): Query text\n",
        "            top_k (int): Number of top similar cases to return\n",
        "\n",
        "        Returns:\n",
        "            list: List of tuples (case_id, similarity_score, case_info)\n",
        "        \"\"\"\n",
        "        # Transform query to TF-IDF vector\n",
        "        query_vector = self.tfidf_vectorizer.transform([query_text])\n",
        "\n",
        "        # Calculate cosine similarity\n",
        "        similarities = cosine_similarity(query_vector, self.tfidf_matrix).flatten()\n",
        "\n",
        "        # Get top-k most similar cases\n",
        "        top_indices = similarities.argsort()[-top_k:][::-1]\n",
        "\n",
        "        results = []\n",
        "        for idx in top_indices:\n",
        "            case_info = {\n",
        "                'case_id': self.df.iloc[idx]['case_id'],\n",
        "                'jenis_perkara': self.df.iloc[idx]['jenis_perkara'],\n",
        "                'pasal': self.df.iloc[idx]['pasal'],\n",
        "                'ringkasan_fakta': self.df.iloc[idx]['ringkasan_fakta'],\n",
        "                'putusan': self.df.iloc[idx]['putusan'],\n",
        "                'similarity_score': float(similarities[idx])\n",
        "            }\n",
        "            results.append((self.df.iloc[idx]['case_id'], similarities[idx], case_info))\n",
        "\n",
        "        return results\n",
        "\n",
        "    def retrieve_bert(self, query_text, top_k=5):\n",
        "        \"\"\"\n",
        "        Retrieve similar cases using BERT embeddings\n",
        "\n",
        "        Args:\n",
        "            query_text (str): Query text\n",
        "            top_k (int): Number of top similar cases to return\n",
        "\n",
        "        Returns:\n",
        "            list: List of tuples (case_id, similarity_score, case_info)\n",
        "        \"\"\"\n",
        "        # Get BERT embedding for query\n",
        "        query_text = str(query_text)[:512]\n",
        "        inputs = self.bert_tokenizer(\n",
        "            query_text,\n",
        "            return_tensors='pt',\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            max_length=512\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.bert_model(**inputs)\n",
        "            query_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
        "\n",
        "        # Calculate cosine similarity with all case embeddings\n",
        "        similarities = cosine_similarity([query_embedding], self.bert_embeddings).flatten()\n",
        "\n",
        "        # Get top-k most similar cases\n",
        "        top_indices = similarities.argsort()[-top_k:][::-1]\n",
        "\n",
        "        results = []\n",
        "        for idx in top_indices:\n",
        "            case_info = {\n",
        "                'case_id': self.df.iloc[idx]['case_id'],\n",
        "                'jenis_perkara': self.df.iloc[idx]['jenis_perkara'],\n",
        "                'pasal': self.df.iloc[idx]['pasal'],\n",
        "                'ringkasan_fakta': self.df.iloc[idx]['ringkasan_fakta'],\n",
        "                'putusan': self.df.iloc[idx]['putusan'],\n",
        "                'similarity_score': float(similarities[idx])\n",
        "            }\n",
        "            results.append((self.df.iloc[idx]['case_id'], similarities[idx], case_info))\n",
        "\n",
        "        return results\n",
        "\n",
        "    def retrieve(self, query_text, method='tfidf', top_k=5):\n",
        "        \"\"\"\n",
        "        Main retrieval function\n",
        "\n",
        "        Args:\n",
        "            query_text (str): Query text\n",
        "            method (str): 'tfidf' or 'bert'\n",
        "            top_k (int): Number of top similar cases to return\n",
        "\n",
        "        Returns:\n",
        "            list: List of retrieved cases\n",
        "        \"\"\"\n",
        "        if method.lower() == 'tfidf':\n",
        "            return self.retrieve_tfidf(query_text, top_k)\n",
        "        elif method.lower() == 'bert':\n",
        "            return self.retrieve_bert(query_text, top_k)\n",
        "        else:\n",
        "            raise ValueError(\"method must be 'tfidf' or 'bert'\")\n",
        "\n",
        "    def create_test_queries(self, num_queries=10):\n",
        "        \"\"\"\n",
        "        Create test queries from existing cases\n",
        "\n",
        "        Args:\n",
        "            num_queries (int): Number of test queries to create\n",
        "\n",
        "        Returns:\n",
        "            list: List of test queries with ground truth\n",
        "        \"\"\"\n",
        "        print(f\"Creating {num_queries} test queries...\")\n",
        "\n",
        "        # Ensure we don't sample more queries than we have cases\n",
        "        actual_num_queries = min(num_queries, len(self.df))\n",
        "\n",
        "        # Sample random cases for queries\n",
        "        sample_indices = np.random.choice(len(self.df), actual_num_queries, replace=False)\n",
        "\n",
        "        queries = []\n",
        "        for idx in sample_indices:\n",
        "            case = self.df.iloc[idx]\n",
        "\n",
        "            # Create query from ringkasan_fakta or first part of text\n",
        "            if pd.notna(case['ringkasan_fakta']) and str(case['ringkasan_fakta']).strip():\n",
        "                query_text = str(case['ringkasan_fakta'])\n",
        "            elif pd.notna(case['argumen_hukum']) and str(case['argumen_hukum']).strip():\n",
        "                query_text = str(case['argumen_hukum'])[:200]\n",
        "            else:\n",
        "                query_text = str(case['retrieval_text'])[:200]\n",
        "\n",
        "            query = {\n",
        "                'query_id': f'query_{len(queries)+1:03d}',\n",
        "                'query_text': query_text.strip(),\n",
        "                'ground_truth_case_id': case['case_id'],\n",
        "                'expected_jenis_perkara': str(case['jenis_perkara']) if pd.notna(case['jenis_perkara']) else 'unknown',\n",
        "                'expected_pasal': str(case['pasal']) if pd.notna(case['pasal']) else 'unknown',\n",
        "                'source_index': int(idx)\n",
        "            }\n",
        "            queries.append(query)\n",
        "\n",
        "        print(f\"Created {len(queries)} test queries\")\n",
        "        return queries\n",
        "\n",
        "    def evaluate_retrieval(self, queries, method='tfidf', top_k=5):\n",
        "        \"\"\"\n",
        "        Evaluate retrieval performance\n",
        "\n",
        "        Args:\n",
        "            queries (list): List of test queries\n",
        "            method (str): Retrieval method\n",
        "            top_k (int): Number of top results to consider\n",
        "\n",
        "        Returns:\n",
        "            dict: Evaluation metrics\n",
        "        \"\"\"\n",
        "        print(f\"Evaluating retrieval with {method} method...\")\n",
        "\n",
        "        hits_at_1 = 0\n",
        "        hits_at_k = 0\n",
        "        mrr_scores = []\n",
        "\n",
        "        for query in queries:\n",
        "            results = self.retrieve(query['query_text'], method=method, top_k=top_k)\n",
        "\n",
        "            # Check if ground truth is in top-1\n",
        "            if results[0][0] == query['ground_truth_case_id']:\n",
        "                hits_at_1 += 1\n",
        "\n",
        "            # Check if ground truth is in top-k\n",
        "            retrieved_ids = [result[0] for result in results]\n",
        "            if query['ground_truth_case_id'] in retrieved_ids:\n",
        "                hits_at_k += 1\n",
        "                # Calculate reciprocal rank\n",
        "                rank = retrieved_ids.index(query['ground_truth_case_id']) + 1\n",
        "                mrr_scores.append(1.0 / rank)\n",
        "            else:\n",
        "                mrr_scores.append(0.0)\n",
        "\n",
        "        metrics = {\n",
        "            'hits_at_1': hits_at_1 / len(queries),\n",
        "            f'hits_at_{top_k}': hits_at_k / len(queries),\n",
        "            'mrr': np.mean(mrr_scores),\n",
        "            'total_queries': len(queries)\n",
        "        }\n",
        "\n",
        "        return metrics\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "    # Initialize system\n",
        "    dataset_path = '/content/drive/MyDrive/PENALARAN KOMPUTER FIX/cases.csv'\n",
        "    retrieval_system = CaseRetrievalSystem(dataset_path)\n",
        "\n",
        "    try:\n",
        "        # Load and preprocess data\n",
        "        df = retrieval_system.load_data()\n",
        "        print(f\"Data shape: {df.shape}\")\n",
        "        print(f\"Columns: {list(df.columns)}\")\n",
        "\n",
        "        # Show sample of jenis_perkara distribution\n",
        "        print(f\"\\nJenis Perkara distribution:\")\n",
        "        perkara_counts = df['jenis_perkara'].value_counts()\n",
        "        print(perkara_counts.head(10))\n",
        "\n",
        "        # Create representations\n",
        "        print(\"\\n=== Creating TF-IDF Representation ===\")\n",
        "        tfidf_matrix = retrieval_system.create_tfidf_representation()\n",
        "\n",
        "        print(\"\\n=== Creating BERT Representation ===\")\n",
        "        bert_embeddings = retrieval_system.create_bert_representation()\n",
        "\n",
        "        # Split data\n",
        "        print(\"\\n=== Splitting Data ===\")\n",
        "        X_train, X_test, y_train, y_test = retrieval_system.split_data(test_size=0.3)\n",
        "\n",
        "        # Train ML model\n",
        "        print(\"\\n=== Training ML Model ===\")\n",
        "        ml_model = retrieval_system.train_ml_model(model_type='svm')\n",
        "\n",
        "        # Create test queries\n",
        "        print(\"\\n=== Creating Test Queries ===\")\n",
        "        test_queries = retrieval_system.create_test_queries(num_queries=min(10, len(df)))\n",
        "\n",
        "        # Create directory and save test queries\n",
        "        eval_dir = '/content/drive/MyDrive/PENALARAN KOMPUTER FIX/data/eval'\n",
        "        os.makedirs(eval_dir, exist_ok=True)\n",
        "\n",
        "        queries_file = os.path.join(eval_dir, 'queries.json')\n",
        "        with open(queries_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(test_queries, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        print(f\"Test queries saved to {queries_file}\")\n",
        "\n",
        "        # Evaluate retrieval\n",
        "        if len(test_queries) > 0:\n",
        "            print(\"\\n=== Evaluating TF-IDF Retrieval ===\")\n",
        "            tfidf_metrics = retrieval_system.evaluate_retrieval(test_queries, method='tfidf', top_k=5)\n",
        "            print(f\"TF-IDF Metrics: {tfidf_metrics}\")\n",
        "\n",
        "            print(\"\\n=== Evaluating BERT Retrieval ===\")\n",
        "            bert_metrics = retrieval_system.evaluate_retrieval(test_queries, method='bert', top_k=5)\n",
        "            print(f\"BERT Metrics: {bert_metrics}\")\n",
        "\n",
        "        # Test retrieval function with sample queries\n",
        "        print(\"\\n=== Testing Retrieval Function ===\")\n",
        "        sample_queries = [\n",
        "            \"kasus perceraian dengan harta gono gini\",\n",
        "            \"sengketa kontrak kerja\",\n",
        "            \"gugatan wanprestasi pembayaran\",\n",
        "            \"pembatalan perjanjian jual beli\"\n",
        "        ]\n",
        "\n",
        "        for sample_query in sample_queries[:2]:  # Test first 2 queries\n",
        "            print(f\"\\n\" + \"=\"*50)\n",
        "            print(f\"Query: {sample_query}\")\n",
        "            print(\"=\"*50)\n",
        "\n",
        "            try:\n",
        "                print(\"\\nTF-IDF Results:\")\n",
        "                tfidf_results = retrieval_system.retrieve(sample_query, method='tfidf', top_k=3)\n",
        "                for i, (case_id, score, info) in enumerate(tfidf_results, 1):\n",
        "                    print(f\"{i}. Case ID: {case_id}, Score: {score:.4f}\")\n",
        "                    print(f\"   Jenis Perkara: {info['jenis_perkara']}\")\n",
        "                    print(f\"   Pasal: {info['pasal']}\")\n",
        "                    print(f\"   Ringkasan: {str(info['ringkasan_fakta'])[:100]}...\")\n",
        "                    print()\n",
        "            except Exception as e:\n",
        "                print(f\"Error in TF-IDF retrieval: {e}\")\n",
        "\n",
        "            try:\n",
        "                print(\"BERT Results:\")\n",
        "                bert_results = retrieval_system.retrieve(sample_query, method='bert', top_k=3)\n",
        "                for i, (case_id, score, info) in enumerate(bert_results, 1):\n",
        "                    print(f\"{i}. Case ID: {case_id}, Score: {score:.4f}\")\n",
        "                    print(f\"   Jenis Perkara: {info['jenis_perkara']}\")\n",
        "                    print(f\"   Pasal: {info['pasal']}\")\n",
        "                    print(f\"   Ringkasan: {str(info['ringkasan_fakta'])[:100]}...\")\n",
        "                    print()\n",
        "            except Exception as e:\n",
        "                print(f\"Error in BERT retrieval: {e}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"=== Case Retrieval System Setup Complete ===\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Save system summary\n",
        "        summary = {\n",
        "            \"dataset_info\": {\n",
        "                \"total_cases\": len(df),\n",
        "                \"tfidf_features\": tfidf_matrix.shape[1],\n",
        "                \"bert_embedding_dim\": bert_embeddings.shape[1],\n",
        "                \"unique_jenis_perkara\": len(df['jenis_perkara'].unique())\n",
        "            },\n",
        "            \"split_info\": {\n",
        "                \"train_size\": len(X_train),\n",
        "                \"test_size\": len(X_test),\n",
        "                \"test_ratio\": len(X_test) / (len(X_train) + len(X_test))\n",
        "            },\n",
        "            \"model_info\": {\n",
        "                \"ml_model_trained\": ml_model is not None,\n",
        "                \"model_type\": type(ml_model).__name__ if ml_model else None\n",
        "            },\n",
        "            \"evaluation\": {\n",
        "                \"num_test_queries\": len(test_queries),\n",
        "                \"tfidf_metrics\": tfidf_metrics if 'tfidf_metrics' in locals() else None,\n",
        "                \"bert_metrics\": bert_metrics if 'bert_metrics' in locals() else None\n",
        "            }\n",
        "        }\n",
        "\n",
        "        summary_file = os.path.join(eval_dir, 'system_summary.json')\n",
        "        with open(summary_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(summary, f, ensure_ascii=False, indent=2, default=str)\n",
        "\n",
        "        print(f\"System summary saved to {summary_file}\")\n",
        "\n",
        "        return retrieval_system\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in main execution: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run the main function\n",
        "    system = main()"
      ]
    }
  ]
}